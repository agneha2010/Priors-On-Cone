library(rnhanesdata)
## load the data
data("PAXINTEN_C");data("PAXINTEN_D")
timevec <- function(x){
mat <- matrix(x, 60, 24)
return(array(colMeans(mat, na.rm = T)))
}
View(PAXINTEN_C)
y <- as.matrix(PAXINTEN_C[, 6:ncol(PAXINTEN_C)])
dim(y)
ydata <- apply(y, 1, timevec)
ydata <- t(ydata)
dim(ydata)
ydata[1,]
subfreq <- array(table(PAXINTEN_C$SEQN))
subfreq
sub  <- unique(PAXINTEN_C$SEQN)
sub
length(sub)
7176*7
timevec <- function(x){
mat <- matrix(x, 60, 24)
return(array(colMeans(mat, na.rm = T)))
}
y <- as.matrix(PAXINTEN_C[, 6:ncol(PAXINTEN_C)])
ydata <- apply(y, 1, timevec)
ydata <- t(ydata)
subfreq <- array(table(PAXINTEN_C$SEQN))
sub  <- unique(PAXINTEN_C$SEQN)
#samp <- sample(sub, 100)
#sub1 <- unique(PAXINTEN_D$SEQN)
#y <- apply(PAXINTEN_C[, 6:ncol(PAXINTEN_D)], 1, function(x){diff(range(x))})
#x <- PAXINTEN_C[, 4]
covar_ls <- rnhanesdata::process_covar(waves=c("C","D"),
varnames = c("SDDSRVYR","WTMEC2YR", "WTINT2YR",
"SDMVPSU", "SDMVSTRA",
"RIDAGEMN", "RIDAGEEX", "RIDAGEYR", "RIDRETH1", "RIAGENDR",
"BMXWT", "BMXHT", "BMXBMI", "DMDEDUC2",
"ALQ101", "ALQ110", "ALQ120Q","ALQ120U", "ALQ130", "SMQ020", "SMD030", "SMQ040",
"MCQ220","MCQ160F", "MCQ160B", "MCQ160C",
"PFQ049","PFQ054","PFQ057","PFQ059", "PFQ061B", "PFQ061C", "DIQ010"))
#y <- apply(PAXINTEN_C[, 6:ncol(PAXINTEN_C)], 1, mean)
Covariate_C <- covar_ls$Covariate_C
Covariate_D <- covar_ls$Covariate_D
indr <- which(Covariate_C$SEQN %in% PAXINTEN_C$SEQN)
Covariate_Cr <- Covariate_C[indr, ]
Covariate_Cr$EducationAdult <- factor(Covariate_Cr$DMDEDUC2, levels=c(1,2,3,4,5,7,9),
labels=c("Less than 9th grade","9-11th grade","High school grad/GED or equivalent",
"Some College or AA degree", "College graduate or above","Refused","Don't know"), ordered=FALSE)
#Inclusion criteria
ind1 <- which(as.numeric(Covariate_Cr$RIDAGEYR) <40 & as.numeric(Covariate_Cr$RIDAGEYR) > 30 & Covariate_Cr$EducationAdult == "College graduate or above")
samsub <- Covariate_Cr$SEQN[ind1]
#samsub <- sample(samsub, 200)
ind <- which(PAXINTEN_C$SEQN %in% samsub)
ydatar <- ydata[ind, ]
Sind1 <- (0:(nrow(ydatar)/7-1))*7+1
Sind2 <- (0:(nrow(ydatar)/7-1))*7+2
Sind3 <- (0:(nrow(ydatar)/7-1))*7+3
Sind4 <- (0:(nrow(ydatar)/7-1))*7+4
Sind5 <- (0:(nrow(ydatar)/7-1))*7+5
Sind6 <- (0:(nrow(ydatar)/7-1))*7+6
Sind7 <- (0:(nrow(ydatar)/7-1))*7+7
plot(Sind1[1,])
dim(Sind1)
length(Sind1)
dim(ydatar)
ydata1 <- ydatar[Sind1, ]
plot(ydata1[1,])
plot(ydata1[1,],type="l")
plot(ydata1[2,],type="l")
plot(ydata1[3,],type="l")
# rm(list=ls())
## Please read these comments before running the code contained in this R script!
##
## In order for the code to execute, users need to set the object: dir_supplemental (line 133)
## to be the parent directory of the "code" folder contained in the supplemental material.
## For additional details regarding the analyses performed here, please refer to the manuscript.
##
## The code below is divided into the following "chunks"
##  - Section 0: Install and load all necessary packages including the rnhanesdata package
##               which contains the accelerometry data used in our analysis.
##  - Section 1:
##              1a. Load and merge accelerometry, demographic/comorbidity, and mortality data
##              1b. Create new factor variables which we will use in our analysis.
##                  * We collapse most comorbidity data into either "Yes", "No", or msising from NHANES
##                    questionairre data which allows for "don't know" or "refused" as responses.
##                     We assume individuals who respond "don't know" or "missing" do not have that particular condition.
##                  * We collapse adult education into 3 levels: "less than high school", "high school", and "more than highschool"
##                  * We add a "missing" level to alcohol consumption in order to retain individuals with missing data
##                    for this item in our analysis.
##
##  - Section 2: Calculate commonly used accelerometry summary measures:
##                 * TAC: Total activity counts
##                 * TLAC: Total log(1+activity countss)
##                 * WT: Total wear time
##                 * ST: Total sedentary, sleep, or non-wear time
##                 * MVPA: Total time spent in MVPA
##                 * SATP: Transition probability from sedentary, sleep, or non-wear to active. In the manuscript this is referred to
##                         using the subscript sl/nw
##                 * ASTP: Transition probability from active to sedentary, sleep, or non-wear. In the manuscript this is referred to
##                         using the subscript sl/nw
##               Note that in this section these variables are calculated at the day level. After applying exlcusion criteria
##               in Section 3, we average across days within individuals to get one number per measure for each participant.
##               The exclusion criteria involves excluding days which are deemed to have insufficient wear-time (<10 hours)
##
##  - Section 3: Apply exclusion criteria and create a data frame with one row per subject which will be used as a basis for regression
##               analyses. This data frame is called "data_analysis".
##
##               When estimating complex survey generalized linear models, we create a svydesign() object via the survey package which
##               uses "data_analysis". In order to fit models which use both  the "adjusted" or "unadjusted" survey weights, we create two separate
##               svydesign() objects. This is done in Section 4.d when we perform forward selection.
##
##               Once we've subset the data to obtain "data_analysis", we calculate both adjusted and unadjsuted normalized
##               survey weights. These weights are calculated using the reweight_accel() function
##               (see ?reweight_accel for details). The adjusted weights are calculated using age, gender,
##               and ethnicity strata. The "adjusted" normalizaed weights we use for regression analyses are "wtmec4yr_adj_norm"
##
##               Ecxlusion criteria
##                 * Apply age exclusion (i.e. younger than 50, or 85 and over). Note that individuals age 85 and over
##                   at the time of accelerometer wear have NA (missing) values for the variable RIDAGEEX which records
##                   age in months at the time individuals took part in the exam portion of the study.
##                 * Create a table of pairwise missing data on variables that we intend to include in our prediction model to
##                   see the distribution of missing data. In our analysis individuals are only excluded for:
##                      - Missing body mass index (BMI)
##                      - Missing education
##                      - "Bad" accelerometry data
##                              + fewer than 3 days of accelerometry data with at least 10 hours of estimated wear-time
##                              + device calibration flag recorded by NHANES
##                              + data reliability flag recorded by NHANES
##                      - Missing mortality data
##                      - Individuals recorded as "alive" but had fewer than 5 years of follow-up
##
##  - Section 4: Data analysis
##              4a. Perform (unweighted) functional principal component analysis (FPCA) and survey weighted PCA
##              4b. Use backward selection to identify FPCA features associated with 5-year mortality. Find surrogate measures on
##                  the log transformed activity counts that correlate strongly with the features which are associated with 5-year mortality.
##              4c. Perform scalar on function regression (SoFR) where we include individuals' average (log-transformed) activity profiles
##                  as the functional predictor.
##              4d. Use forward selection to evaluate the predictive value of our set of variables identified in 4b/4c as well as the commonly used
##                  accelerometry features calculated in Section 2 of this code.
##
##                  * Note that functional forms are assumed to be linear and no interactions/effect modifications are considered.
##
##
##
##  By default, the assummption is that this R script will be downloaded with the supplemental material which accompanies
##  the manuscript "Organizing and analyzing the activity in NHANES". This supplemental material is a zipped file with 3 folders:
##    - code
##    - figures
##    - tables
##  Assuming users correctly set the variable "dir_supplemental",
##  running this script will save all figure output to the "figures" folder and
##  .tex files which contain the latex version of tables presented in the manuscript.
##
##  Because the data are relatively large and require a non-trivial amount of working memory (RAM)
##  we "clean up" the workspace as we go, clearing items after the relevant figures/tables/regression results are
##  created/printed to the console. This may need to be taken into consideration if there's a particualr area you'd like to investigate in more detail.
##
##  Finally, although most of the code executes fairly quickly, there are two sections that may take a few minutes to run.
##  The first, calculating survey weighted principal components, will not execute by default. This can be changed by switching
##  make_plot_fpca_vs_svypca to TRUE in Section 0.
##  The other chunk that takes time to run is the forward selection procedure. There's a print statement embedded in the code that will
##  report progress on the procedure, but this may take 15-25 minutes to completely finish.
########################################
##                                    ##
##  Section 0: load required packages ##
##                                    ##
########################################
## Check for packages needed to run analyses/install the rnhanesdata package.
## Note: all these packages are available on CRAN and can therefore be downloaded using the install.packages() function,
##       the rnhanesdata package is not on CRAN due to package size
pckgs <- c("tableone","knitr","kableExtra",   ## packages used for creating Table 1
"devtools",                        ## package used to download R packages stored on GitHub
"magrittr","dplyr",                ## packages for merging/transforming data
"survey",                          ## package used for analyzing complex survey data in R
"mgcv","refund"                    ## packages used for smoothing/functional regression
)
sapply(pckgs, function(x) if(!require(x,character.only=TRUE,quietly=TRUE)) {
install.packages(x)
require(x, character.only=TRUE)
})
rm(list=c("pckgs"))
library(rnhanesdata)
## Install the rnhanesdata package and dependencies.
## This may take a few minutes because of the size of the data package.
if(!require("rnhanesdata")){
install_github("andrew-leroux/rnhanesdata")
require("rnhanesdata")
}
make_plots  <- TRUE  ## change to FALSE if you don't want to create the figures presented in the manuscript
make_tables <- TRUE  ## change to FALSE if you don't want to create the tables presented in the manuscript
## change "make_plot_fpca_vs_svypca" below to TRUE if you want to plot the first 16 survey weighted principal components versus
## the unweighted functional principal components
make_plot_fpca_vs_svypca <- FALSE
dir_supplemental <- ".."  ## directory where supplemental material folder is saved
code_path        <- file.path(dir_supplemental, "supplemental_material", "code")     ## file path where helper functions and code to create figures are located
figure_path      <- file.path(dir_supplemental, "supplemental_material", "figures")  ## file path where figures will be saved
table_path       <- file.path(dir_supplemental, "supplemental_material", "tables")   ## file path where tables will be saved
## Source a single helper function: calc_weighted_AUC().
## This  function calculates survey weighted AUC given a set of labels and predictions
source(file.path(code_path,"helper_fns.R"))
#######################################
##                                   ##
##  Section 1a: load and merge data  ##
##                                   ##
#######################################
## load the data
data("PAXINTEN_C");data("PAXINTEN_D")
data("Flags_C");data("Flags_D")
#data("Mortality_2011_C");data("Mortality_2011_D")
data("Covariate_C");data("Covariate_D")
data("Mortality_2015_C");data("Mortality_2015_D")
#test <- subset(Mortality_2015_C,!Mortality_2015_C$SEQN %in% Mortality_2011_C$SEQN)
## re-code activity counts which are considered "non-wear" to be 0
## this doesn't impact much data, most estimated non-wear times correspond to 0 counts anyway
PAXINTEN_C[,paste0("MIN",1:1440)] <- PAXINTEN_C[,paste0("MIN",1:1440)]*Flags_C[,paste0("MIN",1:1440)]
PAXINTEN_D[,paste0("MIN",1:1440)] <- PAXINTEN_D[,paste0("MIN",1:1440)]*Flags_D[,paste0("MIN",1:1440)]
## Merge covariate, mortality, and accelerometry data
## note that both PAXINTEN_* and Covariate_* have a column
## called "SDDSRVYR" indicating which NHANES wave the data is associated with.
## To avoid duplicating this column in the merged data, we add this variable to the "by"
## argument in left_join()
AllAct_C <- left_join(PAXINTEN_C, Mortality_2015_C, by = "SEQN") %>%
left_join(Covariate_C, by=c("SEQN", "SDDSRVYR"))
AllAct_D <- left_join(PAXINTEN_D, Mortality_2015_D, by = "SEQN") %>%
left_join(Covariate_D, by=c("SEQN", "SDDSRVYR"))
AllFlags_C <- left_join(Flags_C, Mortality_2015_C, by = "SEQN") %>%
left_join(Covariate_C, by=c("SEQN", "SDDSRVYR"))
AllFlags_D <- left_join(Flags_D, Mortality_2015_D, by = "SEQN") %>%
left_join(Covariate_D, by=c("SEQN", "SDDSRVYR"))
## clean up the workspace for memory purposes
rm(list=c(paste0(c("PAXINTEN_", "Covariate_","Mortality_2015_","Flags_"),rep(LETTERS[3:4],each=4))))
## combine data for the two waves
AllAct   <- rbind.data.frame(AllAct_C,AllAct_D)
AllFlags <- rbind.data.frame(AllFlags_C,AllFlags_D)
## clean up the workspace again
rm(list=c("AllAct_C","AllAct_D","AllFlags_C","AllFlags_D"))
##############################################################################
##                                                                          ##
##  Section 1b: create new variables/relevel factor variables for analyses  ##
##                                                                          ##
##############################################################################
## Code year 5 mortality, NAs for individuals with follow up less than 5 years and alive
AllAct$yr5_mort <- AllFlags$yr5_mort <- as.integer(ifelse(AllAct$permth_exm/12 <= 5 & AllAct$mortstat == 1, 1,
ifelse(AllAct$permth_exm/12 < 5 & AllAct$mortstat == 0, NA, 0))
)
## Create Age in years using the age at examination (i.e. when participants wore the device)
AllAct$Age <- AllFlags$Age <- AllAct$RIDAGEEX/12
## Re-level comorbidities to assign refused/don't know as not having the condition
## Note that in practice this does not affect many individuals, but it is an assumption we're making.
levels(AllAct$CHD)    <- levels(AllFlags$CHD)    <- list("No" = c("No","Refused","Don't know"), "Yes" = c("Yes"))
levels(AllAct$CHF)    <- levels(AllFlags$CHF)    <- list("No" = c("No","Refused","Don't know"), "Yes" = c("Yes"))
levels(AllAct$Stroke) <- levels(AllFlags$Stroke) <- list("No" = c("No","Refused","Don't know"), "Yes" = c("Yes"))
levels(AllAct$Cancer) <- levels(AllFlags$Cancer) <- list("No" = c("No","Refused","Don't know"), "Yes" = c("Yes"))
levels(AllAct$Diabetes) <- levels(AllFlags$Diabetes) <- list("No" = c("No","Borderline", "Refused","Don't know"), "Yes" = c("Yes"))
## Re-level education to have 3 levels and categorize don't know/refused to be missing
levels(AllAct$EducationAdult) <- levels(AllFlags$EducationAdult) <- list("Less than high school" = c("Less than 9th grade", "9-11th grade"),
"High school" = c("High school grad/GED or equivalent"),
"More than high school" = c("Some College or AA degree", "College graduate or above"))
## Re-level alcohol consumption to include a level for "missing"
levels(AllAct$DrinkStatus) <- levels(AllFlags$DrinkStatus) <- c(levels(AllAct$DrinkStatus), "Missing alcohol")
AllAct$DrinkStatus[is.na(AllAct$DrinkStatus)] <- AllFlags$DrinkStatus[is.na(AllAct$DrinkStatus)] <- "Missing alcohol"
## Re-order columns so that activity and wear/non-wear flags are the last 1440 columns of our two
## data matrices. This is a personal preference and is absolutely not necessary.
act_cols <- which(colnames(AllAct) %in% paste0("MIN",1:1440))
oth_cols <- which(!colnames(AllAct) %in% paste0("MIN",1:1440))
AllAct   <- AllAct[,c(oth_cols,act_cols)]
AllFlags <- AllFlags[,c(oth_cols,act_cols)]
rm(list=c("act_cols","oth_cols"))
###########################################################
##                                                       ##
##  Section 2: Calcualte common accelerometery features  ##
##                                                       ##
###########################################################
## Assign just the activity and wear/non-wear flag data to matrices.
## This makes computing the features faster but is technically required.
act_mat  <- as.matrix(AllAct[,paste0("MIN",1:1440)])
flag_mat <- as.matrix(AllFlags[,paste0("MIN",1:1440)])
## replace NAs with 0s
## As described in the manuscript, this only affects 501 minutes for 1 day, for one subject
act_mat[is.na(act_mat)]   <- 0
flag_mat[is.na(flag_mat)] <- 0
AllAct$TAC   <- AllFlags$TAC   <- rowSums(act_mat)
AllAct$TLAC  <- AllFlags$TLAC  <- rowSums(log(1+act_mat))
AllAct$WT    <- AllFlags$WT    <- rowSums(flag_mat)
AllAct$ST    <- AllFlags$ST    <- rowSums(act_mat < 100)
AllAct$MVPA  <- AllFlags$MVPA  <- rowSums(act_mat >= 2020)
## calculate fragmentation measures
bout_mat <- apply(act_mat >= 100, 1, function(x){
mat <- rle(x)
sed <- mat$lengths[which(mat$values == FALSE)]
act <- mat$length[mat$values == TRUE]
sed <- ifelse(length(sed) == 0, NA, mean(sed))
act <- ifelse(length(act) == 0, NA, mean(act))
c(sed,act)
})
AllAct$SBout <- AllFlags$SBout <- bout_mat[1,]
AllAct$ABout <- AllFlags$ABout <- bout_mat[2,]
AllAct$SATP  <- AllFlags$SATP  <- 1/AllAct$SBout
AllAct$ASTP  <- AllFlags$ASTP  <- 1/AllAct$ABout
rm(list=c("act_mat","flag_mat","bout_mat"))
###########################################
##                                       ##
##  Section 3: Apply exclusion criteria  ##
##                                       ##
###########################################
## make dataframe with one row per individual to create table 1.
## Remove columns associated with activity to avoid any confusion.
table_dat <- AllAct[!duplicated(AllAct$SEQN),-which(colnames(AllAct) %in% c(paste0("MIN",1:1440),
"TAC","TLAC","WT","ST","MVPA",
"SBout","ABout","SATP","ASTP"))]
## subset based on our age inclusion/exclusion criteria
## note that individuals age 85 and over are coded as NA
table_dat <- subset(table_dat, !(Age < 50 | is.na(Age)))
## get the SEQN (id variable) associated with individuals with fewer than 3 days accelerometer wear time
## with at least 10 hours OR had their data quality/device calibration flagged by NHANES
keep_inx       <- exclude_accel(AllAct, AllFlags)
Act_Analysis   <- AllAct[keep_inx,]
Flags_Analysis <- AllFlags[keep_inx,]
nms_rm         <- unique(c(Act_Analysis$SEQN[-which(Act_Analysis$SEQN %in% names(table(Act_Analysis$SEQN))[table(Act_Analysis$SEQN)>=3])],
setdiff(AllAct$SEQN, Act_Analysis$SEQN))
)
rm(list=c("keep_inx"))
## Additional inclusion/exclusion criteria.
## Aside from mortality or accelerometer weartime, the only missingness is in
## Education (6) and BMI (35).
criteria_vec <- c("(is.na(table_dat$BMI_cat))",         # missing BMI
"(is.na(table_dat$EducationAdult))",  # missing education
"(table_dat$SEQN %in% nms_rm)",       # too few "good" days of accelerometery data
"((!table_dat$eligstat %in% 1) | is.na(table_dat$mortstat) | is.na(table_dat$permth_exm))") # missing mortality data, or accidental death
## create matrix of pairwise missing data based on our exclusion criterial
tab_miss <- matrix(NA, ncol=length(criteria_vec), nrow=length(criteria_vec))
for(i in seq_along(criteria_vec)){
for(j in seq_along(criteria_vec)){
eval(parse(text=paste0("miss_cur <- which(", criteria_vec[i], "&", criteria_vec[j],")")))
tab_miss[i,j] <- length(miss_cur)
rm(list=c("miss_cur"))
}
}
rownames(tab_miss) <- colnames(tab_miss) <- c("BMI","Education","Bad Accel Data","Mortality")
rm(list=c("i","j"))
## view missing data pattern
tab_miss
## add in column indicating exclusion:
##   Exclude = 1 indicates an individual does not meet our inclusion criteria
##   Exclude = 0 indicates an individual does meet our inclusion criteria
eval(parse(text=paste0("table_dat$Exclude <- as.integer(", paste0(criteria_vec,collapse="|"), ")")))
#saveRDS(table_dat,"table_dat_2015.rds")
## Create our dataset for analysis with one row per subject
## containing only those subjects who meet our inclusion criteria.
data_analysis  <- subset(table_dat, Exclude == 0)
data_analysis$mortstat <- ifelse((data_analysis$ucod_leading %in% "004" & data_analysis$mortstat ==1),0,data_analysis$mortstat)
## get adjusted survey weights using the reweight_accel function
# data_analysis  <- reweight_accel(data_analysis)
## Get activity/flag data for only those included participants AND who have 3 good days of data.
## Since we've already removed the "bad" days from Act_Analysis and Act_Flags,
## we need only subset based on subject ID now.
Act_Analysis   <- subset(Act_Analysis, SEQN %in% data_analysis$SEQN)
Flags_Analysis <- subset(Flags_Analysis, SEQN %in% data_analysis$SEQN)
## calculate subject specific averages of the accelerometry features
## using only the "good" days of data
act_var_nms <- c("TAC","TLAC","WT","ST","MVPA","SATP","ASTP")
for(i in act_var_nms){
data_analysis[[i]] <- vapply(data_analysis$SEQN, function(x) mean(Act_Analysis[[i]][Act_Analysis$SEQN==x],na.rm=TRUE), numeric(1))
}
## verify there's no missingness in the rest of our predictors of interest
vars_interest <- c("Age", "Gender", "Race", "EducationAdult", "SmokeCigs", "DrinkStatus", "BMI_cat",
"Diabetes","CHF",  "CHD", "Stroke",
"Cancer", "MobilityProblem",
"permth_exm")
# summary(data_analysis[,c(vars_interest,act_var_nms,"mortstat")])
# summary(data_analysis$permth_exm)
## clean up the workspace
rm(list=c("AllAct","AllFlags","i","criteria_vec","nms_rm","tab_miss"))
gc()
data_analysis$time <- data_analysis$permth_exm/12
dim(data_analysis)
